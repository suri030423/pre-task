파일 구조 잡기

대학원 과제/
├─ data/
│  ├─ train/
│  │  ├─ images/
│  │  └─ masks/
│  ├─ val/
│  │  ├─ images/
│  │  └─ masks/
│  └─ test/
│     ├─ images/
│     └─ masks/
│
├─ src/
│  ├─ model.py         # U-Net 구조
│  ├─ dataloader.py    # Kaggle dataset
│  ├─ train.py         # 학습 루프
│  ├─ eval.py          # 평가 / 시각화
│  └─ util.py          # 공용 함수
│
└─ README.md


[데이터 전처리]
Kaggle DSB2018 원본 데이터는 instance mask 여러 장으로 구성
이를 binary mask로 합치는 과정 구현
train/val/test 7:1.5:1.5 split 적용
최종 구조는 data/train/images, data/train/masks 형태로 구성
reproducibility를 위해 원본 stage1_train/ 폴더도 함께 보관

eval.py
→ 학습된 U-Net을 로드해서 val / test에 대한 성능 평가 + 시각화
(Dice, IoU 같은 지표 계산, 예측 마스크 몇 장 그림으로 확인)

util.py
→ 여기저기서 공통으로 쓰는 유틸 함수 모음
(logits → mask 변환, Dice/IoU 계산, 시각화용 보조 함수 등)





✔ batch size = 1
→ 맞음. 너 그대로 사용 중.

✔ optimizer = SGD + momentum 0.99
→ 논문 그대로. 너 코드에 그대로 들어있음.
(Adam 쓰면 논문 느낌 사라짐)

✔ lr = 1e-3
→ 논문 기본 튜닝 그대로.

✔ 구형 conv padding 없는 valid architecture → crop 필요
→ 너 코드에는 center crop까지 구현해둠. 이것도 논문 감성.

✔ early best validation loss에서 저장
→ 너 코드: val loss 최소 시 best 저장. 논문도 동일.

✔ epoch 늘릴수록 무조건 좋아지는 구조가 아니다
→ 실제 논문에서도 10~20 epoch 사이에서 성능이 plateau.